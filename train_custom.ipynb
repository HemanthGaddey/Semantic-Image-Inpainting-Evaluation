{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.data_loader import dataloader\n",
    "\n",
    "#importing pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#importing the models\n",
    "from model.base_function import init_net\n",
    "#from model.base_model import BaseModel\n",
    "from model.cnn_encoder import CNN_ENCODER\n",
    "from model.rnn_encoder import RNN_ENCODER\n",
    "from model.attention_textual_resnet_encoder import AttTextualResEncoder\n",
    "from model.hidden_resnet_generator import HiddenResGenerator\n",
    "from model.resnet_discriminator import ResDiscriminator\n",
    "\n",
    "#importing untilities\n",
    "from model import base_function, external_function\n",
    "from util import task, util\n",
    "import itertools\n",
    "from options.global_config import TextConfig\n",
    "import pickle\n",
    "import copy\n",
    "import time\n",
    "\n",
    "###\n",
    "from options.train_options import TrainOptions\n",
    "from model import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self, \n",
    "                 name='fake/real_classifier', \n",
    "                 model='tdanet', \n",
    "                 mask_type=[1, 2, 3], \n",
    "                 checkpoints_dir='./checkpoints', \n",
    "                 which_iter='latest',\n",
    "                 gpu_ids=[],\n",
    "                 text_config = 'config.bird.yml',\n",
    "                 output_scale=4,\n",
    "                 img_file='/data/dataset/train', \n",
    "                 mask_file='none',\n",
    "                 loadSize=[266,266],\n",
    "                 fineSize=[256, 256],\n",
    "                 resize_or_crop='resize_and_crop',\n",
    "                 no_flip=False,\n",
    "                 no_rotation=False,\n",
    "                 no_augment=False,                 \n",
    "                 batchSize=10, \n",
    "                 nThreads=8,\n",
    "                 no_shuffle=False,\n",
    "                 display_winsize=256,\n",
    "                 display_id=1,\n",
    "                 display_port=8097,\n",
    "                 display_single_pane_ncols = 0,\n",
    "                 prior_alpha=0.8, \n",
    "                 prior_beta=8,\n",
    "                 no_maxpooling=False,\n",
    "                 update_language=False,\n",
    "                 detach_embedding=False,\n",
    "                 train_paths='two', \n",
    "                 dynamic_sigma=False, \n",
    "                 lambda_rec_l1=20.0, \n",
    "                 lambda_gen_l1=20.0, \n",
    "                 lambda_kl=20.0, \n",
    "                 lambda_gan=1.0,\n",
    "                 lambda_match=0.1,\n",
    "                 iter_count=1, \n",
    "                 niter=100,\n",
    "                 niter_decay=0,\n",
    "                 continue_train=False,\n",
    "                 valid_file='/data/dataset/valid',\n",
    "                 lr_policy='lambda', \n",
    "                 lr=1e-4, \n",
    "                 gan_mode='lsgan',\n",
    "                 display_freq=100,\n",
    "                 print_freq=100,\n",
    "                 save_latest_freq=1000,\n",
    "                 save_iters_freq=10000,\n",
    "                 no_html=False,\n",
    "                 \n",
    "                 results_dir='./results/',\n",
    "                 phase='test',\n",
    "                 nsampling=50,\n",
    "                 ncaptions=10,\n",
    "                 save_number=10,\n",
    "                 no_variance=False,\n",
    "                ):\n",
    "        \n",
    "        self.name=name\n",
    "        self.model=model\n",
    "        self.mask_type=mask_type\n",
    "        self.img_file=img_file # has paths of all the images\n",
    "        self.mask_file=mask_file\n",
    "        self.checkpoints_dir = checkpoints_dir\n",
    "        self.which_iter = which_iter\n",
    "        self.gpu_ids = gpu_ids\n",
    "        self.text_config = text_config\n",
    "        self.output_scale=output_scale\n",
    "        self.batchSize=batchSize\n",
    "        self.loadSize = loadSize\n",
    "        self.resize_or_crop=resize_or_crop\n",
    "        self.no_flip=no_flip\n",
    "        self.no_rotation = no_rotation\n",
    "        self.no_augment = no_augment\n",
    "        self.nThreads = nThreads,\n",
    "        self.no_shuffle=no_shuffle\n",
    "        self.display_winsize = display_winsize\n",
    "        self.display_id = display_id\n",
    "        self.display_port = display_port\n",
    "        self.fineSize=fineSize\n",
    "        self.display_single_pane_ncols = display_single_pane_ncols\n",
    "        self.no_maxpooling = no_maxpooling\n",
    "        self.update_language = update_language\n",
    "        self.detach_embedding = detach_embedding\n",
    "        self.prior_alpha=prior_alpha\n",
    "        self.prior_beta=prior_beta\n",
    "        self.gan_mode=gan_mode\n",
    "        self.no_variance=no_variance\n",
    "        self.nsampling=nsampling\n",
    "        self.train_paths=train_paths\n",
    "        self.dynamic_sigma=dynamic_sigma\n",
    "        self.lambda_rec_l1=lambda_rec_l1\n",
    "        self.lambda_gen_l1=lambda_gen_l1\n",
    "        self.lambda_kl=lambda_kl\n",
    "        self.lambda_gan=lambda_gan\n",
    "        self.lambda_match=lambda_match\n",
    "        self.iter_count = iter_count\n",
    "        self.niter = niter\n",
    "        self.niter_decay = niter_decay\n",
    "        self.continue_train = continue_train\n",
    "        self.valid_file = valid_file\n",
    "        self.lr_policy = lr_policy\n",
    "        self.lr = lr\n",
    "        self.display_freq = display_freq\n",
    "        self.print_freq = print_freq\n",
    "        self.save_latest_freq = save_latest_freq\n",
    "        self.save_iters_freq = save_iters_freq\n",
    "        self.no_html = no_html\n",
    "        \n",
    "        self.results_dir=results_dir\n",
    "        self.phase=phase\n",
    "        self.nsampling=nsampling\n",
    "        self.ncaptions=ncaptions\n",
    "        self.save_number=save_number\n",
    "        self.no_variance=no_variance\n",
    "        \n",
    "        self.isTrain = True #MAKE IT FALSE WHEN TESTING!!!\n",
    "        \n",
    "\n",
    "opt=Options(name='tda_bird',model=\"tdanet\",mask_type=[0,1,2,3],img_file='./datasets/CUB_200_2011/train.flist',mask_file='./datasets/CUB_200_2011/train_mask.flist',text_config='config.bird.yml') #TRAINING OPTIONS, CHANGE FOR TESTING!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CONFIG = {\n",
    "    'MAX_TEXT_LENGTH' : 128,\n",
    "\n",
    "    'VOCAB' : \"./datasets/captions_vocab_bird.pickle\",      # The path to DAMSM vocab pickle file\n",
    "    'LANGUAGE_ENCODER' : \"./datasets/text_encoder_bird.pth\",    # The path to DAMSM text encoder\n",
    "    'IMAGE_ENCODER': \"./datasets/image_encoder_bird.pth\",   # The path to DAMSM image encoder\n",
    "    'EMBEDDING_DIM' : 256,\n",
    "\n",
    "    'CATE_IMAGE_TRAIN' : \"./datasets/CUB_200_2011/cate_image_train.json\",   # The path to category-image mapping cache file\n",
    "    'IMAGE_CATE_TRAIN' : \"./datasets/CUB_200_2011/image_cate.json\",     # The path to image-category mapping cache file\n",
    "\n",
    "    'CAPTION' : \"./datasets/CUB_200_2011/caption.json\",     # The path to image-caption cache file\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for generating masks\n",
    "def scale_pyramid(img, num_scales):\n",
    "    scaled_imgs = [img]\n",
    "\n",
    "    s = img.size()\n",
    "\n",
    "    h = s[2]\n",
    "    w = s[3]\n",
    "\n",
    "    for i in range(1, num_scales):\n",
    "        ratio = 2**i\n",
    "        nh = h // ratio\n",
    "        nw = w // ratio\n",
    "        scaled_img = scale_img(img, size=[nh, nw])\n",
    "        scaled_imgs.append(scaled_img)\n",
    "\n",
    "    scaled_imgs.reverse()\n",
    "    return scaled_imgs\n",
    "\n",
    "# scaling images\n",
    "def scale_img(img, size):\n",
    "    scaled_img = F.interpolate(img, size=size, mode='bilinear', align_corners=True)\n",
    "    return scaled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDAnet:\n",
    "    def __init__(self, opt):\n",
    "        \n",
    "        self.loss_names = ['kl_rec', 'kl_g', 'l1_rec', 'l1_g', 'gan_g', 'word_g', 'sentence_g', 'ad_l2_g',\n",
    "                           'gan_rec', 'ad_l2_rec', 'word_rec', 'sentence_rec',  'dis_img', 'dis_img_rec']\n",
    "        self.log_names = []\n",
    "        self.visual_names = ['img_m', 'img_truth', 'img_c', 'img_out', 'img_g', 'img_rec']\n",
    "        self.text_names = ['text_positive']\n",
    "        self.value_names = ['u_m', 'sigma_m', 'u_post', 'sigma_post', 'u_prior', 'sigma_prior']\n",
    "        self.model_names = ['E', 'G', 'D', 'D_rec']\n",
    "        self.distribution = []\n",
    "        self.prior_alpha = opt.prior_alpha\n",
    "        self.prior_beta = opt.prior_beta\n",
    "        self.max_pool = None if opt.no_maxpooling else 'max'\n",
    "\n",
    "        # inpainting model\n",
    "        self.net_E = network.define_att_textual_e(ngf=32, z_nc=256, img_f=256, layers=5, norm='none', activation='LeakyReLU',\n",
    "                          init_type='orthogonal', gpu_ids=opt.gpu_ids, image_dim=256, text_dim=256, multi_peak=False, pool_attention=self.max_pool)\n",
    "        self.net_G = network.define_hidden_textual_g(f_text_dim=768, ngf=32, z_nc=256, img_f=256, L=0, layers=5, output_scale=opt.output_scale,\n",
    "                                      norm='instance', activation='LeakyReLU', init_type='orthogonal', gpu_ids=opt.gpu_ids)\n",
    "        \n",
    "        #discriminator model\n",
    "        self.net_D = network.define_d(ndf=32, img_f=128, layers=5, model_type='ResDis', init_type='orthogonal', gpu_ids=opt.gpu_ids)\n",
    "        self.net_D_rec = network.define_d(ndf=32, img_f=128, layers=5, model_type='ResDis', init_type='orthogonal', gpu_ids=opt.gpu_ids)\n",
    "\n",
    "        self._init_language_model(DEFAULT_CONFIG)\n",
    "\n",
    "        if self.isTrain:\n",
    "            # define the loss functions\n",
    "            self.GANloss = external_function.GANLoss(opt.gan_mode)\n",
    "            self.L1loss = torch.nn.L1Loss()\n",
    "            self.L2loss = torch.nn.MSELoss()\n",
    "\n",
    "            self.image_encoder = network.CNN_ENCODER(DEFAULT_CONFIG['EMBEDDING_DIM'])\n",
    "            state_dict = torch.load(\n",
    "                DEFAULT_CONFIG['IMAGE_ENCODER'], map_location=lambda storage, loc: storage)\n",
    "            self.image_encoder.load_state_dict(state_dict)\n",
    "            self.image_encoder.eval()\n",
    "            if len(self.gpu_ids) > 0 and torch.cuda.is_available():\n",
    "                self.image_encoder.cuda()\n",
    "            base_function._freeze(self.image_encoder)\n",
    "\n",
    "            # define the optimizer\n",
    "            self.optimizer_G = torch.optim.Adam(itertools.chain(filter(lambda p: p.requires_grad, self.net_G.parameters()),\n",
    "                        filter(lambda p: p.requires_grad, self.net_E.parameters())), lr=opt.lr, betas=(0.0, 0.999))\n",
    "            self.optimizer_D = torch.optim.Adam(itertools.chain(filter(lambda p: p.requires_grad, self.net_D.parameters()),\n",
    "                                                filter(lambda p: p.requires_grad, self.net_D_rec.parameters())),\n",
    "                                                lr=opt.lr, betas=(0.0, 0.999))\n",
    "            self.optimizers.append(self.optimizer_G)\n",
    "            self.optimizers.append(self.optimizer_D)\n",
    "\n",
    "        self.setup(opt)\n",
    "\n",
    "        def _init_language_model(self, text_config):\n",
    "            x = pickle.load(open(text_config['VOCAB'], 'rb'))\n",
    "            self.ixtoword = x[2]\n",
    "            self.wordtoix = x[3]\n",
    "\n",
    "            word_len = len(self.wordtoix)\n",
    "            self.text_encoder = network.RNN_ENCODER(word_len, nhidden=256)\n",
    "\n",
    "            state_dict = torch.load(text_config['LANGUAGE_ENCODER'], map_location=lambda storage, loc: storage)\n",
    "            self.text_encoder.load_state_dict(state_dict)\n",
    "            self.text_encoder.eval()\n",
    "            if not self.opt.update_language:\n",
    "                self.text_encoder.requires_grad_(False)\n",
    "            if len(self.gpu_ids) > 0 and torch.cuda.is_available():\n",
    "                self.text_encoder.cuda()\n",
    "\n",
    "        def set_input(self, input, epoch=0):\n",
    "            \"\"\"Unpack input data from the data loader and perform necessary pre-process steps\"\"\"\n",
    "            self.input = input\n",
    "            self.image_paths = self.input['img_path']\n",
    "            self.img = input['img']\n",
    "            self.mask = input['mask']\n",
    "            self.caption_idx = input['caption_idx']\n",
    "            self.caption_length = input['caption_len']\n",
    "\n",
    "            if len(self.gpu_ids) > 0:\n",
    "                self.img = self.img.cuda(self.gpu_ids[0], True)\n",
    "                self.mask = self.mask.cuda(self.gpu_ids[0], True)\n",
    "\n",
    "            # get I_m and I_c for image with mask and complement regions for training\n",
    "            self.img_truth = self.img * 2 - 1\n",
    "            self.img_m = self.mask * self.img_truth\n",
    "            self.img_c =  (1 - self.mask) * self.img_truth\n",
    "\n",
    "            # get multiple scales image ground truth and mask for training\n",
    "            self.scale_img = scale_pyramid(self.img_truth, self.opt.output_scale)\n",
    "            self.scale_mask = scale_pyramid(self.mask, self.opt.output_scale)\n",
    "\n",
    "            # About text stuff\n",
    "            self.text_positive = util.idx_to_caption(\n",
    "                                        self.ixtoword, self.caption_idx[0].tolist(), self.caption_length[0].item())\n",
    "            self.word_embeddings, self.sentence_embedding = util.vectorize_captions_idx_batch(\n",
    "                                                        self.caption_idx, self.caption_length, self.text_encoder)\n",
    "            self.text_mask = util.lengths_to_mask(self.caption_length, max_length=self.word_embeddings.size(-1))\n",
    "            self.match_labels = torch.LongTensor(range(len(self.img_m)))\n",
    "            if len(self.gpu_ids) > 0:\n",
    "                self.word_embeddings = self.word_embeddings.cuda(self.gpu_ids[0], True)\n",
    "                self.sentence_embedding = self.sentence_embedding.cuda(self.gpu_ids[0], True)\n",
    "                self.text_mask = self.text_mask.cuda(self.gpu_ids[0], True)\n",
    "                self.match_labels = self.match_labels.cuda(self.gpu_ids[0], True)\n",
    "        \n",
    "        def test(self, mark=None):\n",
    "            \"\"\"Forward function used in test time\"\"\"\n",
    "            # save the groundtruth and masked image\n",
    "            self.save_results(self.img_truth, data_name='truth')\n",
    "            self.save_results(self.img_m, data_name='mask')\n",
    "\n",
    "            # encoder process\n",
    "            distribution, f, f_text = self.net_E(\n",
    "                self.img_m, self.sentence_embedding, self.word_embeddings, self.text_mask, self.mask)\n",
    "            variation_factor = 0. if opt.no_variance else 1.\n",
    "            q_distribution = torch.distributions.Normal(distribution[-1][0], distribution[-1][1] * variation_factor)\n",
    "            scale_mask = scale_img(self.mask, size=[f[2].size(2), f[2].size(3)])\n",
    "\n",
    "            # decoder process\n",
    "            for i in range(opt.nsampling):\n",
    "                z = q_distribution.sample()\n",
    "\n",
    "                self.img_g, attn = self.net_G(z, f_text, f_e=f[2], mask=scale_mask.chunk(3, dim=1)[0])\n",
    "                self.img_out = (1 - self.mask) * self.img_g[-1].detach() + self.mask * self.img_m\n",
    "                self.score = self.net_D(self.img_out)\n",
    "                self.save_results(self.img_out, i, data_name='out', mark=mark)\n",
    "        \n",
    "        def get_distribution(self, distribution_factors):\n",
    "            \"\"\"Calculate encoder distribution for img_m, img_c only in train, all about distribution layer of VAE model\"\"\"\n",
    "            # get distribution\n",
    "            sum_valid = (torch.mean(self.mask.view(self.mask.size(0), -1), dim=1) - 1e-5).view(-1, 1, 1, 1)\n",
    "            m_sigma = 1 if not self.opt.dynamic_sigma else (1 / (1 + ((sum_valid - self.prior_alpha) * self.prior_beta).exp_()))\n",
    "            p_distribution, q_distribution, kl_rec, kl_g = 0, 0, 0, 0\n",
    "            self.distribution = []\n",
    "            for distribution in distribution_factors:\n",
    "                p_mu, p_sigma, q_mu, q_sigma = distribution\n",
    "                # the assumption distribution for different mask regions\n",
    "                std_distribution = torch.distributions.Normal(torch.zeros_like(p_mu), m_sigma * torch.ones_like(p_sigma))\n",
    "                # m_distribution = torch.distributions.Normal(torch.zeros_like(p_mu), torch.ones_like(p_sigma))\n",
    "                # the post distribution from mask regions\n",
    "                p_distribution = torch.distributions.Normal(p_mu, p_sigma)\n",
    "                p_distribution_fix = torch.distributions.Normal(p_mu.detach(), p_sigma.detach())\n",
    "                # the prior distribution from valid region\n",
    "                q_distribution = torch.distributions.Normal(q_mu, q_sigma)\n",
    "\n",
    "                # kl divergence\n",
    "                kl_rec += torch.distributions.kl_divergence(std_distribution, p_distribution)\n",
    "                if self.opt.train_paths == \"one\":\n",
    "                    kl_g += torch.distributions.kl_divergence(std_distribution, q_distribution)\n",
    "                elif self.opt.train_paths == \"two\":\n",
    "                    kl_g += torch.distributions.kl_divergence(p_distribution_fix, q_distribution)\n",
    "                self.distribution.append([torch.zeros_like(p_mu), m_sigma * torch.ones_like(p_sigma), p_mu, p_sigma, q_mu, q_sigma])\n",
    "\n",
    "            return p_distribution, q_distribution, kl_rec, kl_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDAnet():\n",
    "#     @staticmethod\n",
    "#     def modify_options(parser, is_train=True):\n",
    "#         \"\"\"Add new options and rewrite default values for existing options\"\"\"\n",
    "#         parser.add_argument('--prior_alpha', type=float, default=0.8,\n",
    "#                             help='factor to contorl prior variation: 1/(1+e^((x-0.8)*8))')\n",
    "#         parser.add_argument('--prior_beta', type=float, default=8,\n",
    "#                             help='factor to contorl prior variation: 1/(1+e^((x-0.8)*8))')\n",
    "#         parser.add_argument('--no_maxpooling', action='store_true', help='rm maxpooling in DMA for ablation')\n",
    "#         parser.add_argument('--update_language', action='store_true', help='update language encoder while training')\n",
    "#         parser.add_argument('--detach_embedding', action='store_true',\n",
    "#                             help='do not pass grad to embedding in DAMSM-text end')\n",
    "\n",
    "#         if is_train:\n",
    "#             parser.add_argument('--train_paths', type=str, default='two', help='training strategies with one path or two paths')\n",
    "#             parser.add_argument('--dynamic_sigma', action='store_true', help='change sigma base on mask area')\n",
    "#             parser.add_argument('--lambda_rec_l1', type=float, default=20.0, help='weight for image reconstruction loss')\n",
    "#             parser.add_argument('--lambda_gen_l1', type=float, default=20.0, help='weight for image reconstruction loss')\n",
    "#             parser.add_argument('--lambda_kl', type=float, default=20.0, help='weight for kl divergence loss')\n",
    "#             parser.add_argument('--lambda_gan', type=float, default=1.0, help='weight for generation loss')\n",
    "#             parser.add_argument('--lambda_match', type=float, default=0.1, help='weight for image-text match loss')\n",
    "\n",
    "#         return parser\n",
    "\n",
    "    def __init__(self, opt):\n",
    "        \"\"\"Initial the pluralistic model\"\"\"\n",
    "        #BaseModel.__init__(self, opt)\n",
    "\n",
    "        self.loss_names = ['kl_rec', 'kl_g', 'l1_rec', 'l1_g', 'gan_g', 'word_g', 'sentence_g', 'ad_l2_g',\n",
    "                           'gan_rec', 'ad_l2_rec', 'word_rec', 'sentence_rec',  'dis_img', 'dis_img_rec']\n",
    "        self.log_names = []\n",
    "        self.visual_names = ['img_m', 'img_truth', 'img_c', 'img_out', 'img_g', 'img_rec']\n",
    "        self.text_names = ['text_positive']\n",
    "        self.value_names = ['u_m', 'sigma_m', 'u_post', 'sigma_post', 'u_prior', 'sigma_prior']\n",
    "        self.model_names = ['E', 'G', 'D', 'D_rec']\n",
    "        self.distribution = []\n",
    "        self.prior_alpha = opt.prior_alpha\n",
    "        self.prior_beta = opt.prior_beta\n",
    "        self.max_pool = None if opt.no_maxpooling else 'max'\n",
    "\n",
    "        ''' define the inpainting model '''\n",
    "        self.net_E = AttTextualResEncoder(input_nc=3, ngf=32, z_nc=256, img_f=256, L=6, layers=5, norm='none', activation='LeakyReLU', use_spect=True, use_coord=False, image_dim=256, text_dim=256, multi_peak=False, pool_attention=self.max_pool)\n",
    "        self.net_E = init_net(self.net_E, init_type='orthogonal', activation='ReLU', gpu_ids=opt.gpu_ids)\n",
    "\n",
    "\n",
    "        self.net_G = HiddenResGenerator(output_nc=3, f_text_dim=768, ngf=32, z_nc=256, img_f=256, L=0, layers=5, norm='instance', activation='LeakyReLU', output_scale=opt.output_scale, use_spect=True, use_coord=False, use_attn=True)\n",
    "        self.net_G = init_net(self.net_G, init_type='orthogonal', activation='LeakyReLU', gpu_ids=opt.gpu_ids)\n",
    "\n",
    "        ''' define the discriminator model '''\n",
    "        self.net_D = ResDiscriminator(input_nc=3, ndf=32, img_f=128, layers=5, norm='none', activation='LeakyReLU', use_spect=True, use_coord=False, use_attn=True)\n",
    "        self.net_D = init_net(self.net_D, init_type='orthogonal', activation='LeakyReLU', gpu_ids=opt.gpu_ids)\n",
    "        self.net_D_rec = copy.deepcopy(self.net_D)\n",
    "\n",
    "        text_config = TextConfig(opt.text_config)\n",
    "        self._init_language_model(text_config)\n",
    "\n",
    "        if self.isTrain:\n",
    "            # define the loss functions\n",
    "            self.GANloss = external_function.GANLoss(opt.gan_mode)\n",
    "            self.L1loss = torch.nn.L1Loss()\n",
    "            self.L2loss = torch.nn.MSELoss()\n",
    "\n",
    "            self.image_encoder = CNN_ENCODER(text_config.EMBEDDING_DIM)\n",
    "            state_dict = torch.load(\n",
    "                text_config.IMAGE_ENCODER, map_location=lambda storage, loc: storage)\n",
    "            self.image_encoder.load_state_dict(state_dict)\n",
    "            self.image_encoder.eval()\n",
    "            if len(self.gpu_ids) > 0 and torch.cuda.is_available():\n",
    "                self.image_encoder.cuda()\n",
    "            base_function._freeze(self.image_encoder)\n",
    "\n",
    "            # define the optimizer\n",
    "            self.optimizer_G = torch.optim.Adam(itertools.chain(filter(lambda p: p.requires_grad, self.net_G.parameters()),\n",
    "                        filter(lambda p: p.requires_grad, self.net_E.parameters())), lr=opt.lr, betas=(0.0, 0.999))\n",
    "            self.optimizer_D = torch.optim.Adam(itertools.chain(filter(lambda p: p.requires_grad, self.net_D.parameters()),\n",
    "                                                filter(lambda p: p.requires_grad, self.net_D_rec.parameters())),\n",
    "                                                lr=opt.lr, betas=(0.0, 0.999))\n",
    "            self.optimizers.append(self.optimizer_G)\n",
    "            self.optimizers.append(self.optimizer_D)\n",
    "\n",
    "        self.setup(opt)\n",
    "\n",
    "    def _init_language_model(self, text_config):\n",
    "        x = pickle.load(open(text_config.VOCAB, 'rb'))\n",
    "        self.ixtoword = x[2]\n",
    "        self.wordtoix = x[3]\n",
    "\n",
    "        word_len = len(self.wordtoix)\n",
    "        self.text_encoder = RNN_ENCODER(word_len, nhidden=256)\n",
    "\n",
    "        state_dict = torch.load(text_config.LANGUAGE_ENCODER, map_location=lambda storage, loc: storage)\n",
    "        self.text_encoder.load_state_dict(state_dict)\n",
    "        self.text_encoder.eval()\n",
    "        if not self.opt.update_language:\n",
    "            self.text_encoder.requires_grad_(False)\n",
    "        if len(self.gpu_ids) > 0 and torch.cuda.is_available():\n",
    "            self.text_encoder.cuda()\n",
    "\n",
    "    def set_input(self, input, epoch=0):\n",
    "        \"\"\"Unpack input data from the data loader and perform necessary pre-process steps\"\"\"\n",
    "        self.input = input\n",
    "        self.image_paths = self.input['img_path']\n",
    "        self.img = input['img']\n",
    "        self.mask = input['mask']\n",
    "        self.caption_idx = input['caption_idx']\n",
    "        self.caption_length = input['caption_len']\n",
    "\n",
    "        if len(self.gpu_ids) > 0:\n",
    "            self.img = self.img.cuda(self.gpu_ids[0], True)\n",
    "            self.mask = self.mask.cuda(self.gpu_ids[0], True)\n",
    "\n",
    "        # get I_m and I_c for image with mask and complement regions for training\n",
    "        self.img_truth = self.img * 2 - 1\n",
    "        self.img_m = self.mask * self.img_truth\n",
    "        self.img_c =  (1 - self.mask) * self.img_truth\n",
    "\n",
    "        # get multiple scales image ground truth and mask for training\n",
    "        self.scale_img = task.scale_pyramid(self.img_truth, self.opt.output_scale)\n",
    "        self.scale_mask = task.scale_pyramid(self.mask, self.opt.output_scale)\n",
    "\n",
    "        # About text stuff\n",
    "        self.text_positive = util.idx_to_caption(\n",
    "                                    self.ixtoword, self.caption_idx[0].tolist(), self.caption_length[0].item())\n",
    "        self.word_embeddings, self.sentence_embedding = util.vectorize_captions_idx_batch(\n",
    "                                                    self.caption_idx, self.caption_length, self.text_encoder)\n",
    "        self.text_mask = util.lengths_to_mask(self.caption_length, max_length=self.word_embeddings.size(-1))\n",
    "        self.match_labels = torch.LongTensor(range(len(self.img_m)))\n",
    "        if len(self.gpu_ids) > 0:\n",
    "            self.word_embeddings = self.word_embeddings.cuda(self.gpu_ids[0], True)\n",
    "            self.sentence_embedding = self.sentence_embedding.cuda(self.gpu_ids[0], True)\n",
    "            self.text_mask = self.text_mask.cuda(self.gpu_ids[0], True)\n",
    "            self.match_labels = self.match_labels.cuda(self.gpu_ids[0], True)\n",
    "\n",
    "    def test(self, mark=None):\n",
    "        \"\"\"Forward function used in test time\"\"\"\n",
    "        # save the groundtruth and masked image\n",
    "        self.save_results(self.img_truth, data_name='truth')\n",
    "        self.save_results(self.img_m, data_name='mask')\n",
    "\n",
    "        # encoder process\n",
    "        distribution, f, f_text = self.net_E(\n",
    "            self.img_m, self.sentence_embedding, self.word_embeddings, self.text_mask, self.mask)\n",
    "        variation_factor = 0. if self.opt.no_variance else 1.\n",
    "        q_distribution = torch.distributions.Normal(distribution[-1][0], distribution[-1][1] * variation_factor)\n",
    "        scale_mask = task.scale_img(self.mask, size=[f[2].size(2), f[2].size(3)])\n",
    "\n",
    "        # decoder process\n",
    "        for i in range(self.opt.nsampling):\n",
    "            z = q_distribution.sample()\n",
    "\n",
    "            self.img_g, attn = self.net_G(z, f_text, f_e=f[2], mask=scale_mask.chunk(3, dim=1)[0])\n",
    "            self.img_out = (1 - self.mask) * self.img_g[-1].detach() + self.mask * self.img_m\n",
    "            self.score = self.net_D(self.img_out)\n",
    "            self.save_results(self.img_out, i, data_name='out', mark=mark)\n",
    "\n",
    "    def get_distribution(self, distribution_factors):\n",
    "        \"\"\"Calculate encoder distribution for img_m, img_c only in train, all about distribution layer of VAE model\"\"\"\n",
    "        # get distribution\n",
    "        sum_valid = (torch.mean(self.mask.view(self.mask.size(0), -1), dim=1) - 1e-5).view(-1, 1, 1, 1)\n",
    "        m_sigma = 1 if not self.opt.dynamic_sigma else (1 / (1 + ((sum_valid - self.prior_alpha) * self.prior_beta).exp_()))\n",
    "        p_distribution, q_distribution, kl_rec, kl_g = 0, 0, 0, 0\n",
    "        self.distribution = []\n",
    "        for distribution in distribution_factors:\n",
    "            p_mu, p_sigma, q_mu, q_sigma = distribution\n",
    "            # the assumption distribution for different mask regions\n",
    "            std_distribution = torch.distributions.Normal(torch.zeros_like(p_mu), m_sigma * torch.ones_like(p_sigma))\n",
    "            # m_distribution = torch.distributions.Normal(torch.zeros_like(p_mu), torch.ones_like(p_sigma))\n",
    "            # the post distribution from mask regions\n",
    "            p_distribution = torch.distributions.Normal(p_mu, p_sigma)\n",
    "            p_distribution_fix = torch.distributions.Normal(p_mu.detach(), p_sigma.detach())\n",
    "            # the prior distribution from valid region\n",
    "            q_distribution = torch.distributions.Normal(q_mu, q_sigma)\n",
    "\n",
    "            # kl divergence\n",
    "            kl_rec += torch.distributions.kl_divergence(std_distribution, p_distribution)\n",
    "            if self.opt.train_paths == \"one\":\n",
    "                kl_g += torch.distributions.kl_divergence(std_distribution, q_distribution)\n",
    "            elif self.opt.train_paths == \"two\":\n",
    "                kl_g += torch.distributions.kl_divergence(p_distribution_fix, q_distribution)\n",
    "            self.distribution.append([torch.zeros_like(p_mu), m_sigma * torch.ones_like(p_sigma), p_mu, p_sigma, q_mu, q_sigma])\n",
    "\n",
    "        return p_distribution, q_distribution, kl_rec, kl_g\n",
    "\n",
    "    def get_G_inputs(self, p_distribution, q_distribution, f):\n",
    "        \"\"\"Process the encoder feature and distributions for generation network, combine two dataflow when implement.\"\"\"\n",
    "        f_m = torch.cat([f[-1].chunk(2)[0], f[-1].chunk(2)[0]], dim=0)\n",
    "        f_e = torch.cat([f[2].chunk(2)[0], f[2].chunk(2)[0]], dim=0)\n",
    "        scale_mask = task.scale_img(self.mask, size=[f_e.size(2), f_e.size(3)])\n",
    "        mask = torch.cat([scale_mask.chunk(3, dim=1)[0], scale_mask.chunk(3, dim=1)[0]], dim=0)\n",
    "        z_p = p_distribution.rsample()\n",
    "        z_q = q_distribution.rsample()\n",
    "        z = torch.cat([z_p, z_q], dim=0)\n",
    "        return z, f_m, f_e, mask\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"Run forward processing to get the inputs\"\"\"\n",
    "        # encoder process\n",
    "        distribution_factors, f, f_text = self.net_E(\n",
    "            self.img_m, self.sentence_embedding, self.word_embeddings, self.text_mask, self.mask, self.img_c)\n",
    "\n",
    "        p_distribution, q_distribution, self.kl_rec, self.kl_g = self.get_distribution(distribution_factors)\n",
    "\n",
    "        # decoder process\n",
    "        z, f_m, f_e, mask = self.get_G_inputs(p_distribution, q_distribution, f) # prepare inputs: img, mask, distribute\n",
    "\n",
    "        results, attn = self.net_G(z, f_text, f_e, mask)\n",
    "        self.img_rec = []\n",
    "        self.img_g = []\n",
    "        for result in results:\n",
    "            img_rec, img_g = result.chunk(2)\n",
    "            self.img_rec.append(img_rec)\n",
    "            self.img_g.append(img_g)\n",
    "        self.img_out = (1-self.mask) * self.img_g[-1].detach() + self.mask * self.img_truth\n",
    "\n",
    "        self.region_features_rec, self.cnn_code_rec = self.image_encoder(self.img_rec[-1])\n",
    "        self.region_features_g, self.cnn_code_g = self.image_encoder(self.img_g[-1])\n",
    "\n",
    "\n",
    "    def backward_D_basic(self, netD, real, fake):\n",
    "        \"\"\"Calculate GAN loss for the discriminator\"\"\"\n",
    "        # Real\n",
    "        D_real = netD(real)\n",
    "        D_real_loss = self.GANloss(D_real, True, True)\n",
    "        # fake\n",
    "        D_fake = netD(fake.detach())\n",
    "        D_fake_loss = self.GANloss(D_fake, False, True)\n",
    "        # loss for discriminator\n",
    "        D_loss = (D_real_loss + D_fake_loss) * 0.5\n",
    "        # gradient penalty for wgan-gp\n",
    "        if self.opt.gan_mode == 'wgangp':\n",
    "            gradient_penalty, gradients = external_function.cal_gradient_penalty(netD, real, fake.detach())\n",
    "            D_loss +=gradient_penalty\n",
    "\n",
    "        D_loss.backward()\n",
    "\n",
    "        return D_loss\n",
    "\n",
    "    def backward_D(self):\n",
    "        \"\"\"Calculate the GAN loss for the discriminators\"\"\"\n",
    "        base_function._unfreeze(self.net_D, self.net_D_rec)\n",
    "        ## Note: changed gen path gan loss to rec path\n",
    "        # self.loss_dis_img = self.backward_D_basic(self.net_D, self.img_truth, self.img_g[-1])\n",
    "        self.loss_dis_img = self.backward_D_basic(self.net_D, self.img_truth, self.img_rec[-1])\n",
    "        self.loss_dis_img_rec = self.backward_D_basic(self.net_D_rec, self.img_truth, self.img_rec[-1])\n",
    "\n",
    "    def backward_G(self):\n",
    "        \"\"\"Calculate training loss for the generator\"\"\"\n",
    "\n",
    "        # encoder kl loss\n",
    "        self.loss_kl_rec = self.kl_rec.mean() * self.opt.lambda_kl * self.opt.output_scale\n",
    "        self.loss_kl_g = self.kl_g.mean() * self.opt.lambda_kl * self.opt.output_scale\n",
    "\n",
    "        # Adversarial loss\n",
    "        base_function._freeze(self.net_D, self.net_D_rec)\n",
    "\n",
    "        # D loss fake\n",
    "        D_fake_g = self.net_D(self.img_g[-1])\n",
    "        self.loss_gan_g = self.GANloss(D_fake_g, True, False) * self.opt.lambda_gan\n",
    "        D_fake_rec = self.net_D(self.img_rec[-1])\n",
    "        self.loss_gan_rec = self.GANloss(D_fake_rec, True, False) * self.opt.lambda_gan\n",
    "\n",
    "        # LSGAN loss\n",
    "        D_fake = self.net_D_rec(self.img_rec[-1])\n",
    "        D_real = self.net_D_rec(self.img_truth)\n",
    "        D_fake_g = self.net_D_rec(self.img_g[-1])\n",
    "        self.loss_ad_l2_rec = self.L2loss(D_fake, D_real) * self.opt.lambda_gan\n",
    "        self.loss_ad_l2_g = self.L2loss(D_fake_g, D_real) * self.opt.lambda_gan\n",
    "\n",
    "        # Text-image consistent loss\n",
    "        if not self.opt.detach_embedding:\n",
    "            sentence_embedding = self.sentence_embedding\n",
    "            word_embeddings = self.word_embeddings\n",
    "        else:\n",
    "            sentence_embedding = self.sentence_embedding.detach()\n",
    "            word_embeddings = self.word_embeddings.detach()\n",
    "\n",
    "\n",
    "        loss_sentence = base_function.sent_loss(self.cnn_code_rec, sentence_embedding, self.match_labels)\n",
    "        loss_word, _ = base_function.words_loss(self.region_features_rec, word_embeddings, self.match_labels, \\\n",
    "                                 self.caption_length, len(word_embeddings))\n",
    "        self.loss_word_rec = loss_word * self.opt.lambda_match\n",
    "        self.loss_sentence_rec = loss_sentence * self.opt.lambda_match\n",
    "\n",
    "        loss_sentence = base_function.sent_loss(self.cnn_code_g, sentence_embedding, self.match_labels)\n",
    "        loss_word, _ = base_function.words_loss(self.region_features_g, word_embeddings, self.match_labels, \\\n",
    "                                 self.caption_length, len(word_embeddings))\n",
    "        self.loss_word_g = loss_word * self.opt.lambda_match\n",
    "        self.loss_sentence_g = loss_sentence * self.opt.lambda_match\n",
    "\n",
    "\n",
    "        # calculate l1 loss ofr multi-scale, multi-depth-level outputs\n",
    "        loss_l1_rec, loss_l1_g, log_PSNR_rec, log_PSNR_out = 0, 0, 0, 0\n",
    "        for i, (img_rec_i, img_fake_i, img_out_i, img_real_i, mask_i) in enumerate(zip(self.img_rec, self.img_g, self.img_out, self.scale_img, self.scale_mask)):\n",
    "            loss_l1_rec += self.L1loss(img_rec_i, img_real_i)\n",
    "            if self.opt.train_paths == \"one\":\n",
    "                loss_l1_g += self.L1loss(img_fake_i, img_real_i)\n",
    "            elif self.opt.train_paths == \"two\":\n",
    "                loss_l1_g += self.L1loss(img_fake_i, img_real_i)\n",
    "\n",
    "        self.loss_l1_rec = loss_l1_rec * self.opt.lambda_rec_l1\n",
    "        self.loss_l1_g = loss_l1_g * self.opt.lambda_gen_l1\n",
    "\n",
    "        # if one path during the training, just calculate the loss for generation path\n",
    "        if self.opt.train_paths == \"one\":\n",
    "            self.loss_l1_rec = self.loss_l1_rec * 0\n",
    "            self.loss_ad_l2_rec = self.loss_ad_l2_rec * 0\n",
    "            self.loss_kl_rec = self.loss_kl_rec * 0\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        for name in self.loss_names:\n",
    "            if name != 'dis_img' and name != 'dis_img_rec':\n",
    "                total_loss += getattr(self, \"loss_\" + name)\n",
    "\n",
    "        total_loss.backward()\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        \"\"\"update network weights\"\"\"\n",
    "        # compute the image completion results\n",
    "        self.forward()\n",
    "        # optimize the discrinimator network parameters\n",
    "        self.optimizer_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.optimizer_D.step()\n",
    "        # optimize the completion network parameters\n",
    "        self.optimizer_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.optimizer_G.step()\n",
    "\n",
    "    def save_results(self, save_data, score=None, data_name='none', mark=None):\n",
    "        \"\"\"Save the training or testing results to disk\"\"\"\n",
    "        img_paths = self.get_image_paths()\n",
    "\n",
    "        for i in range(save_data.size(0)):\n",
    "            print('process image ...... %s' % img_paths[i])\n",
    "            short_path = ntpath.basename(img_paths[i])  # get image path\n",
    "            name = os.path.splitext(short_path)[0]\n",
    "            if type(score) == type(None):\n",
    "                img_name = '%s_%s.png' % (name, data_name)\n",
    "            else:\n",
    "                # d_score = score[i].mean()\n",
    "                # img_name = '%s_%s_%s.png' % (name, data_name, str(round(d_score.item(), 3)))\n",
    "                if type(mark) == type(None):\n",
    "                    img_name = '%s_%s_%s.png' % (name, data_name, str(score))\n",
    "                else:\n",
    "                    img_name = '%s_%s_%s_%s.png' % (name, data_name, str(score), str(mark))\n",
    "            # save predicted image with discriminator score\n",
    "            util.mkdir(self.opt.results_dir)\n",
    "            img_path = os.path.join(self.opt.results_dir, img_name)\n",
    "            img_numpy = util.tensor2im(save_data[i].data)\n",
    "            util.save_image(img_numpy, img_path)\n",
    "\n",
    "    # load models\n",
    "    def load_networks(self, which_epoch, gpu_ids):\n",
    "        \"\"\"Load all the networks from the disk\"\"\"\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                filename = '%s_net_%s.pth' % (which_epoch, name)\n",
    "                path = os.path.join(self.save_dir, filename)\n",
    "                net = getattr(self, 'net_' + name)\n",
    "                pretrained_dict = torch.load(path)\n",
    "                try:\n",
    "                    if len(gpu_ids) != 0:\n",
    "                        net.load_state_dict(pretrained_dict)\n",
    "                    else:\n",
    "                        pretrained_dict_cpu = {key[7:]:value for key, value in pretrained_dict.items()}\n",
    "                        net.load_state_dict(pretrained_dict_cpu)\n",
    "                except:\n",
    "                    model_dict = net.state_dict()\n",
    "                    try:\n",
    "                        pretrained_dict = {k:v for k,v in pretrained_dict.items() if k in model_dict}\n",
    "                        net.load_state_dict(pretrained_dict)\n",
    "                        print('Pretrained network %s has excessive layers; Only loading layers that are used' % name)\n",
    "                    except:\n",
    "                        print('Pretrained network %s has fewer layers; The following are not initialized:' % name)\n",
    "                        not_initialized = set()\n",
    "                        for k, v in pretrained_dict.items():\n",
    "                            if v.size() == model_dict[k].size():\n",
    "                                model_dict[k] = v\n",
    "\n",
    "                        for k, v in model_dict.items():\n",
    "                            if k not in pretrained_dict or v.size() != pretrained_dict[k].size():\n",
    "                                not_initialized.add(k.split('.')[0])\n",
    "                        print(sorted(not_initialized))\n",
    "                        net.load_state_dict(model_dict)\n",
    "                if len(self.gpu_ids) > 0 and torch.cuda.is_available():\n",
    "                    net.cuda()\n",
    "                if not self.isTrain:\n",
    "                    net.eval()\n",
    "    def setup(self, opt):\n",
    "        \"\"\"Load networks, create schedulers\"\"\"\n",
    "        if self.isTrain:\n",
    "            self.schedulers = [base_function.get_scheduler(optimizer, opt) for optimizer in self.optimizers]\n",
    "        if not self.isTrain or opt.continue_train:\n",
    "            self.load_networks(opt.which_iter, opt.gpu_ids)\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"Make models eval mode during test time\"\"\"\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                net = getattr(self, 'net_' + name)\n",
    "                net.eval()\n",
    "\n",
    "    def get_image_paths(self):\n",
    "        \"\"\"Return image paths that are used to load current data\"\"\"\n",
    "        return self.image_paths\n",
    "\n",
    "    def update_learning_rate(self):\n",
    "        \"\"\"Update learning rate\"\"\"\n",
    "        for scheduler in self.schedulers:\n",
    "            scheduler.step()\n",
    "        lr = self.optimizers[0].param_groups[0]['lr']\n",
    "        print('learning rate=%.7f' % lr)\n",
    "\n",
    "    def get_current_errors(self):\n",
    "        \"\"\"Return training loss\"\"\"\n",
    "        errors_ret = OrderedDict()\n",
    "        for name in self.loss_names:\n",
    "            if isinstance(name, str):\n",
    "                errors_ret[name] = getattr(self, 'loss_' + name).item()\n",
    "\n",
    "        if 'img_truth' in self.visual_names:\n",
    "            truth = getattr(self, 'img_truth')\n",
    "            outputs_names = ['img_out', 'img_g', 'img_rec']\n",
    "            for name in outputs_names:\n",
    "                if name in self.visual_names:\n",
    "                    out = getattr(self, name)\n",
    "                    psnr = util.PSNR(util.tensor2im(out[-1].data), util.tensor2im(truth[-1].data))\n",
    "                    errors_ret['psnr_'+name] = psnr\n",
    "\n",
    "        return errors_ret\n",
    "\n",
    "    def get_current_visuals(self):\n",
    "        \"\"\"Return visualization images\"\"\"\n",
    "        visual_ret = OrderedDict()\n",
    "        for name in self.visual_names:\n",
    "            if isinstance(name, str):\n",
    "                value = getattr(self, name)\n",
    "                if isinstance(value, list):\n",
    "                    visual_ret[name] = util.tensor2im(value[-1].data)\n",
    "                else:\n",
    "                    visual_ret[name] = util.tensor2im(value.data)\n",
    "        return visual_ret\n",
    "\n",
    "    def get_current_text(self):\n",
    "        \"\"\"Return the last image's caption of current batch\"\"\"\n",
    "        text_ret = OrderedDict()\n",
    "        for name in self.text_names:\n",
    "            if isinstance(name, str):\n",
    "                text = getattr(self, name)\n",
    "                if isinstance(text, list):\n",
    "                    text_ret[name] = text[-1] + '\\n'+ self.image_paths[0]\n",
    "                else:\n",
    "                    text_ret[name] = text + '\\n' + self.image_paths[0]\n",
    "        return text_ret\n",
    "\n",
    "    def get_current_dis(self):\n",
    "        \"\"\"Return the distribution of encoder features\"\"\"\n",
    "        dis_ret = OrderedDict()\n",
    "        value = getattr(self, 'distribution')\n",
    "        for i in range(1):\n",
    "            for j, name in enumerate(self.value_names):\n",
    "                if isinstance(name, str):\n",
    "                    dis_ret[name+str(i)] =util.tensor2array(value[i][j].data)\n",
    "\n",
    "        return dis_ret\n",
    "\n",
    "    # save model\n",
    "    def save_networks(self, which_epoch):\n",
    "        \"\"\"Save all the networks to the disk\"\"\"\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                save_filename = '%s_net_%s.pth' % (which_epoch, name)\n",
    "                save_path = os.path.join(self.save_dir, save_filename)\n",
    "                net = getattr(self, 'net_' + name)\n",
    "                torch.save(net.cpu().state_dict(), save_path)\n",
    "                if len(self.gpu_ids) > 0 and torch.cuda.is_available():\n",
    "                    net.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "a={\"a\":1,\"b\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttTextualResEncoder(\n",
      "  (block0): ResBlockEncoderOptimized(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (1): LeakyReLU(negative_slope=0.1)\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_attention): ImageTextAttention(\n",
      "    (conv_image): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (sm): Softmax(dim=None)\n",
      "    (sigmoid): Sigmoid()\n",
      "    (pooling_layer): AdaptiveMaxPool2d(output_size=1)\n",
      "  )\n",
      "  (encoder0): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder1): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder2): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder3): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (infer_prior0): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (infer_prior1): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (infer_prior2): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (infer_prior3): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (infer_prior4): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (infer_prior5): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (posterior): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (prior): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "total number of parameters: 23.233 M\n",
      "initialize network with orthogonal\n",
      "HiddenResGenerator(\n",
      "  (generator): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): ReLU()\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (f_transformer): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): ReLU()\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder0): ResBlockDecoder(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU()\n",
      "      (5): SpectralNorm(\n",
      "        (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder1): ResBlockDecoder(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU()\n",
      "      (5): SpectralNorm(\n",
      "        (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out1): Output(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(256, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "      )\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (attn1): Auto_Attn(\n",
      "    (query_conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (softmax): Softmax(dim=-1)\n",
      "    (model): ResBlock(\n",
      "      (conv1): SpectralNorm(\n",
      "        (module): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bypass): SpectralNorm(\n",
      "        (module): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (model): Sequential(\n",
      "        (0): LeakyReLU(negative_slope=0.01)\n",
      "        (1): SpectralNorm(\n",
      "          (module): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "        (3): SpectralNorm(\n",
      "          (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): SpectralNorm(\n",
      "          (module): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder2): ResBlockDecoder(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(259, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): ConvTranspose2d(259, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): BatchNorm2d(259, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(259, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU()\n",
      "      (5): SpectralNorm(\n",
      "        (module): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): ConvTranspose2d(259, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out2): Output(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "      )\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (decoder3): ResBlockDecoder(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(131, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): ConvTranspose2d(131, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): BatchNorm2d(131, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(131, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU()\n",
      "      (5): SpectralNorm(\n",
      "        (module): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): ConvTranspose2d(131, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out3): Output(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "      )\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (decoder4): ResBlockDecoder(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(67, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): ConvTranspose2d(67, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): BatchNorm2d(67, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(67, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU()\n",
      "      (5): SpectralNorm(\n",
      "        (module): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): ConvTranspose2d(67, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out4): Output(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "      )\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "total number of parameters: 10.311 M\n",
      "initialize network with orthogonal\n",
      "ResDiscriminator(\n",
      "  (nonlinearity): LeakyReLU(negative_slope=0.1)\n",
      "  (block0): ResBlockEncoderOptimized(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (1): LeakyReLU(negative_slope=0.1)\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder0): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder1): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (attn2): Auto_Attn(\n",
      "    (query_conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (softmax): Softmax(dim=-1)\n",
      "    (model): ResBlock(\n",
      "      (conv1): SpectralNorm(\n",
      "        (module): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bypass): SpectralNorm(\n",
      "        (module): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (model): Sequential(\n",
      "        (0): LeakyReLU(negative_slope=0.01)\n",
      "        (1): SpectralNorm(\n",
      "          (module): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "        (3): SpectralNorm(\n",
      "          (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): SpectralNorm(\n",
      "          (module): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder2): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder3): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (block1): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv): SpectralNorm(\n",
      "    (module): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "total number of parameters: 1.591 M\n",
      "initialize network with orthogonal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hemanthgaddey/Documents/tdanet_/venv3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TDAnet' object has no attribute 'opt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9ac018875735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTDAnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-b255e9b59b76>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mtext_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_language_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misTrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-b255e9b59b76>\u001b[0m in \u001b[0;36m_init_language_model\u001b[0;34m(self, text_config)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_language\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TDAnet' object has no attribute 'opt'"
     ]
    }
   ],
   "source": [
    "model=TDAnet(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
    "]\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "\n",
    "def make_dataset(path_files):\n",
    "    if os.path.isfile(path_files):\n",
    "        paths, size = make_dataset_txt(path_files)\n",
    "    else:\n",
    "        paths, size = make_dataset_dir(path_files)\n",
    "\n",
    "    return paths, size\n",
    "\n",
    "\n",
    "def make_dataset_txt(files):\n",
    "    \"\"\"\n",
    "    :param path_files: the path of txt file that store the image paths\n",
    "    :return: image paths and sizes\n",
    "    \"\"\"\n",
    "    img_paths = []\n",
    "\n",
    "    with open(files) as f:\n",
    "        paths = f.readlines()\n",
    "\n",
    "    for path in paths:\n",
    "        path = path.strip()\n",
    "        img_paths.append(os.path.join(os.path.dirname(files), path))\n",
    "\n",
    "    return img_paths, len(img_paths)\n",
    "\n",
    "\n",
    "def make_dataset_dir(dir):\n",
    "    \"\"\"\n",
    "    :param dir: directory paths that store the image\n",
    "    :return: image paths and sizes\n",
    "    \"\"\"\n",
    "    img_paths = []\n",
    "\n",
    "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
    "\n",
    "    for root, _, fnames in os.walk(dir):\n",
    "        for fname in sorted(fnames):\n",
    "            if is_image_file(fname):\n",
    "                path = os.path.join(root, fname)\n",
    "                img_paths.append(path)\n",
    "\n",
    "    return img_paths, len(img_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio\n",
    "from PIL import Image, ImageFile\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "from util import task, util\n",
    "from options.global_config import TextConfig\n",
    "\n",
    "class CreateDataset(data.Dataset):\n",
    "    def __init__(self, opt, debug=False):\n",
    "        self.opt = opt\n",
    "        self.debug = debug\n",
    "        self.img_paths, self.img_size = make_dataset(opt.img_file)\n",
    "        # provides random file for training and testing\n",
    "        if opt.mask_file != 'none':\n",
    "            if not opt.mask_file.endswith('.json'):\n",
    "                self.mask_paths, self.mask_size = make_dataset(opt.mask_file)\n",
    "            else:\n",
    "                with open(opt.mask_file, 'r') as f:\n",
    "                    self.image_bbox = json.load(f)\n",
    "\n",
    "        self.transform = get_transform(opt)\n",
    "\n",
    "        ## ========Abnout text stuff===============\n",
    "        text_config = TextConfig(opt.text_config)\n",
    "        self.max_length = text_config.MAX_TEXT_LENGTH\n",
    "        if 'coco' in text_config.CAPTION.lower():\n",
    "            self.num_captions = 5\n",
    "        elif 'place' in text_config.CAPTION.lower():\n",
    "            self.num_captions = 1\n",
    "        else:\n",
    "            self.num_captions = 10\n",
    "\n",
    "        # load caption file\n",
    "        with open(text_config.CAPTION, 'r') as f:\n",
    "            self.captions = json.load(f)\n",
    "\n",
    "        x = pickle.load(open(text_config.VOCAB, 'rb'))\n",
    "        self.ixtoword = x[2]\n",
    "        self.wordtoix = x[3]\n",
    "\n",
    "        self.epoch = 0 # Used for iter on captions.\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load image\n",
    "        index = self.epoch*self.img_size+index\n",
    "\n",
    "        img, img_path = self.load_img(index)\n",
    "        # load mask\n",
    "        mask = self.load_mask(img, index, img_path)\n",
    "        assert sum(img.shape) == sum(mask.shape), (img.shape, mask.shape)\n",
    "        caption_idx, caption_len, caption, img_name= self._load_text_idx(index)\n",
    "        return {'img': img, 'img_path': img_path, 'mask': mask, \\\n",
    "                'caption_idx' : torch.Tensor(caption_idx).long(), 'caption_len':caption_len,\\\n",
    "                'caption_text': caption, 'image_path': img_name}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.img_size\n",
    "\n",
    "    def name(self):\n",
    "        return \"inpainting dataset\"\n",
    "\n",
    "    def load_img(self, index):\n",
    "        ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "        img_path = self.img_paths[index % self.img_size]\n",
    "        img_pil = Image.open(img_path).convert('RGB')\n",
    "        img = self.transform(img_pil)\n",
    "        img_pil.close()\n",
    "        return img, img_path\n",
    "\n",
    "    def _load_text_idx(self, image_index):\n",
    "        img_name = self.img_paths[image_index % self.img_size]\n",
    "        caption_index_of_image = image_index // self.img_size  % self.num_captions\n",
    "        img_name = os.path.basename(img_name)\n",
    "        captions = self.captions[img_name]\n",
    "        caption = captions[caption_index_of_image] if type(captions) == list else captions\n",
    "        caption_idx, caption_len = util._caption_to_idx(self.wordtoix, caption, self.max_length)\n",
    "\n",
    "        return caption_idx, caption_len, caption, img_name\n",
    "\n",
    "    def load_mask(self, img, index, img_path):\n",
    "        \"\"\"Load different mask types for training and testing\"\"\"\n",
    "        mask_type_index = random.randint(0, len(self.opt.mask_type) - 1)\n",
    "        mask_type = self.opt.mask_type[mask_type_index]\n",
    "\n",
    "        # center mask\n",
    "        if mask_type == 0:\n",
    "            return task.center_mask(img)\n",
    "\n",
    "        # random regular mask\n",
    "        if mask_type == 1:\n",
    "            return task.random_regular_mask(img)\n",
    "\n",
    "        # random irregular mask\n",
    "        if mask_type == 2:\n",
    "            return task.random_irregular_mask(img)\n",
    "\n",
    "        if mask_type == 3:\n",
    "            # file masks, e.g. CUB object mask\n",
    "            mask_index = index\n",
    "            mask_pil = Image.open(self.mask_paths[mask_index]).convert('RGB')\n",
    "\n",
    "            mask_transform = get_transform_mask(self.opt)\n",
    "\n",
    "            mask = (mask_transform(mask_pil) == 0).float()\n",
    "            mask_pil.close()\n",
    "            return mask\n",
    "\n",
    "        if mask_type == 4:\n",
    "            # coco json file object mask\n",
    "            if os.path.basename(img_path) not in self.image_bbox:\n",
    "                return task.random_regular_mask(img)\n",
    "\n",
    "            img_original = np.asarray(Image.open(img_path).convert('RGB'))\n",
    "\n",
    "            # create a mask matrix same as img_original\n",
    "            mask = np.zeros_like(img_original)\n",
    "            bboxes = self.image_bbox[os.path.basename(img_path)]\n",
    "\n",
    "            # choose max area box\n",
    "            choosen_box = 0,0,0,0\n",
    "            max_area = 0\n",
    "            for x1,x2,y1,y2 in bboxes:\n",
    "                area = (x2-x1) * (y2-y1)\n",
    "                if area > max_area:\n",
    "                    max_area = area\n",
    "                    choosen_box = x1,x2,y1,y2\n",
    "            x1, x2, y1, y2 = choosen_box\n",
    "            mask[x1:x2, y1:y2] = 1\n",
    "\n",
    "            # apply same transform as img to the mask\n",
    "            mask_pil = Image.fromarray(mask)\n",
    "\n",
    "            mask_transform = get_transform_mask(self.opt)\n",
    "\n",
    "            mask = (mask_transform(mask_pil) == 0).float()\n",
    "\n",
    "            mask_pil.close()\n",
    "\n",
    "            return mask\n",
    "\n",
    "def dataloader(opt):\n",
    "    datasets = CreateDataset(opt)\n",
    "    print(datasets,opt.batchSize,opt.no_shuffle,opt.nThreads)\n",
    "    dataset = data.DataLoader(datasets, batch_size=opt.batchSize, shuffle=not opt.no_shuffle, num_workers=int(opt.nThreads[0]), pin_memory=True)\n",
    "    return dataset\n",
    "\n",
    "def get_transform_mask(opt):\n",
    "    \"\"\"Basic process to transform PIL image to torch tensor\"\"\"\n",
    "    transform_list = []\n",
    "    osize = [opt.loadSize[0], opt.loadSize[1]]\n",
    "    fsize = [opt.fineSize[0], opt.fineSize[1]]\n",
    "    if opt.isTrain:\n",
    "        if opt.resize_or_crop == 'resize_and_crop':\n",
    "            transform_list.append(transforms.Resize(osize))\n",
    "            transform_list.append(transforms.RandomCrop(fsize))\n",
    "        elif opt.resize_or_crop == 'crop':\n",
    "            transform_list.append(transforms.RandomCrop(fsize))\n",
    "        if not opt.no_flip:\n",
    "            transform_list.append(transforms.RandomHorizontalFlip())\n",
    "        if not opt.no_rotation:\n",
    "            transform_list.append(transforms.RandomRotation(3))\n",
    "    else:\n",
    "        transform_list.append(transforms.Resize(fsize))\n",
    "\n",
    "    transform_list += [transforms.ToTensor()]\n",
    "\n",
    "    return transforms.Compose(transform_list)\n",
    "\n",
    "def get_transform(opt):\n",
    "    \"\"\"Basic process to transform PIL image to torch tensor\"\"\"\n",
    "    transform_list = []\n",
    "    osize = [opt.loadSize[0], opt.loadSize[1]]\n",
    "    fsize = [opt.fineSize[0], opt.fineSize[1]]\n",
    "    if opt.isTrain:\n",
    "        if opt.resize_or_crop == 'resize_and_crop':\n",
    "            transform_list.append(transforms.Resize(osize))\n",
    "            transform_list.append(transforms.RandomCrop(fsize))\n",
    "        elif opt.resize_or_crop == 'crop':\n",
    "            transform_list.append(transforms.RandomCrop(fsize))\n",
    "        if not opt.no_augment:\n",
    "            transform_list.append(transforms.ColorJitter(0.0, 0.0, 0.0, 0.0))\n",
    "        if not opt.no_flip:\n",
    "            transform_list.append(transforms.RandomHorizontalFlip())\n",
    "        if not opt.no_rotation:\n",
    "            transform_list.append(transforms.RandomRotation(3))\n",
    "    else:\n",
    "        transform_list.append(transforms.Resize(fsize))\n",
    "\n",
    "    transform_list += [transforms.ToTensor()]\n",
    "\n",
    "    return transforms.Compose(transform_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CreateDataset object at 0x7efec63d2a10> 10 False (8,)\n"
     ]
    }
   ],
   "source": [
    "dataset= dataloader(opt)\n",
    "dataset_size = len(dataset) * opt.batchSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training images = 5800\n",
      "hehe0 __name__ model.tdanet_model\n",
      "hehe0 __doc__ None\n",
      "hehe0 __package__ model\n",
      "hehe0 __loader__ <_frozen_importlib_external.SourceFileLoader object at 0x7eff5e4bb2d0>\n",
      "hehe0 __spec__ ModuleSpec(name='model.tdanet_model', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7eff5e4bb2d0>, origin='/home/hemanthgaddey/Documents/tdanet_/tdanet/model/tdanet_model.py')\n",
      "hehe0 __file__ /home/hemanthgaddey/Documents/tdanet_/tdanet/model/tdanet_model.py\n",
      "hehe0 __cached__ /home/hemanthgaddey/Documents/tdanet_/tdanet/model/__pycache__/tdanet_model.cpython-36.pyc\n",
      "hehe0 __builtins__ {'__name__': 'builtins', '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", '__package__': '', '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>), '__build_class__': <built-in function __build_class__>, '__import__': <built-in function __import__>, 'abs': <built-in function abs>, 'all': <built-in function all>, 'any': <built-in function any>, 'ascii': <built-in function ascii>, 'bin': <built-in function bin>, 'callable': <built-in function callable>, 'chr': <built-in function chr>, 'compile': <built-in function compile>, 'delattr': <built-in function delattr>, 'dir': <built-in function dir>, 'divmod': <built-in function divmod>, 'eval': <built-in function eval>, 'exec': <built-in function exec>, 'format': <built-in function format>, 'getattr': <built-in function getattr>, 'globals': <built-in function globals>, 'hasattr': <built-in function hasattr>, 'hash': <built-in function hash>, 'hex': <built-in function hex>, 'id': <built-in function id>, 'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7f008418ffd0>>, 'isinstance': <built-in function isinstance>, 'issubclass': <built-in function issubclass>, 'iter': <built-in function iter>, 'len': <built-in function len>, 'locals': <built-in function locals>, 'max': <built-in function max>, 'min': <built-in function min>, 'next': <built-in function next>, 'oct': <built-in function oct>, 'ord': <built-in function ord>, 'pow': <built-in function pow>, 'print': <built-in function print>, 'repr': <built-in function repr>, 'round': <built-in function round>, 'setattr': <built-in function setattr>, 'sorted': <built-in function sorted>, 'sum': <built-in function sum>, 'vars': <built-in function vars>, 'None': None, 'Ellipsis': Ellipsis, 'NotImplemented': NotImplemented, 'False': False, 'True': True, 'bool': <class 'bool'>, 'memoryview': <class 'memoryview'>, 'bytearray': <class 'bytearray'>, 'bytes': <class 'bytes'>, 'classmethod': <class 'classmethod'>, 'complex': <class 'complex'>, 'dict': <class 'dict'>, 'enumerate': <class 'enumerate'>, 'filter': <class 'filter'>, 'float': <class 'float'>, 'frozenset': <class 'frozenset'>, 'property': <class 'property'>, 'int': <class 'int'>, 'list': <class 'list'>, 'map': <class 'map'>, 'object': <class 'object'>, 'range': <class 'range'>, 'reversed': <class 'reversed'>, 'set': <class 'set'>, 'slice': <class 'slice'>, 'staticmethod': <class 'staticmethod'>, 'str': <class 'str'>, 'super': <class 'super'>, 'tuple': <class 'tuple'>, 'type': <class 'type'>, 'zip': <class 'zip'>, '__debug__': True, 'BaseException': <class 'BaseException'>, 'Exception': <class 'Exception'>, 'TypeError': <class 'TypeError'>, 'StopAsyncIteration': <class 'StopAsyncIteration'>, 'StopIteration': <class 'StopIteration'>, 'GeneratorExit': <class 'GeneratorExit'>, 'SystemExit': <class 'SystemExit'>, 'KeyboardInterrupt': <class 'KeyboardInterrupt'>, 'ImportError': <class 'ImportError'>, 'ModuleNotFoundError': <class 'ModuleNotFoundError'>, 'OSError': <class 'OSError'>, 'EnvironmentError': <class 'OSError'>, 'IOError': <class 'OSError'>, 'EOFError': <class 'EOFError'>, 'RuntimeError': <class 'RuntimeError'>, 'RecursionError': <class 'RecursionError'>, 'NotImplementedError': <class 'NotImplementedError'>, 'NameError': <class 'NameError'>, 'UnboundLocalError': <class 'UnboundLocalError'>, 'AttributeError': <class 'AttributeError'>, 'SyntaxError': <class 'SyntaxError'>, 'IndentationError': <class 'IndentationError'>, 'TabError': <class 'TabError'>, 'LookupError': <class 'LookupError'>, 'IndexError': <class 'IndexError'>, 'KeyError': <class 'KeyError'>, 'ValueError': <class 'ValueError'>, 'UnicodeError': <class 'UnicodeError'>, 'UnicodeEncodeError': <class 'UnicodeEncodeError'>, 'UnicodeDecodeError': <class 'UnicodeDecodeError'>, 'UnicodeTranslateError': <class 'UnicodeTranslateError'>, 'AssertionError': <class 'AssertionError'>, 'ArithmeticError': <class 'ArithmeticError'>, 'FloatingPointError': <class 'FloatingPointError'>, 'OverflowError': <class 'OverflowError'>, 'ZeroDivisionError': <class 'ZeroDivisionError'>, 'SystemError': <class 'SystemError'>, 'ReferenceError': <class 'ReferenceError'>, 'BufferError': <class 'BufferError'>, 'MemoryError': <class 'MemoryError'>, 'Warning': <class 'Warning'>, 'UserWarning': <class 'UserWarning'>, 'DeprecationWarning': <class 'DeprecationWarning'>, 'PendingDeprecationWarning': <class 'PendingDeprecationWarning'>, 'SyntaxWarning': <class 'SyntaxWarning'>, 'RuntimeWarning': <class 'RuntimeWarning'>, 'FutureWarning': <class 'FutureWarning'>, 'ImportWarning': <class 'ImportWarning'>, 'UnicodeWarning': <class 'UnicodeWarning'>, 'BytesWarning': <class 'BytesWarning'>, 'ResourceWarning': <class 'ResourceWarning'>, 'ConnectionError': <class 'ConnectionError'>, 'BlockingIOError': <class 'BlockingIOError'>, 'BrokenPipeError': <class 'BrokenPipeError'>, 'ChildProcessError': <class 'ChildProcessError'>, 'ConnectionAbortedError': <class 'ConnectionAbortedError'>, 'ConnectionRefusedError': <class 'ConnectionRefusedError'>, 'ConnectionResetError': <class 'ConnectionResetError'>, 'FileExistsError': <class 'FileExistsError'>, 'FileNotFoundError': <class 'FileNotFoundError'>, 'IsADirectoryError': <class 'IsADirectoryError'>, 'NotADirectoryError': <class 'NotADirectoryError'>, 'InterruptedError': <class 'InterruptedError'>, 'PermissionError': <class 'PermissionError'>, 'ProcessLookupError': <class 'ProcessLookupError'>, 'TimeoutError': <class 'TimeoutError'>, 'open': <built-in function open>, 'copyright': Copyright (c) 2001-2021 Python Software Foundation.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 2000 BeOpen.com.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
      "All Rights Reserved.\n",
      "\n",
      "Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
      "All Rights Reserved., 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
      "    for supporting Python development.  See www.python.org for more information., 'license': Type license() to see the full license text, 'help': Type help() for interactive help, or help(object) for help about object., '__IPYTHON__': True, 'display': <function display at 0x7f0086a22ef0>, '__pybind11_internals_v3__': <capsule object NULL at 0x7f00840d6e10>, '__pybind11_internals_v3_gcc_libstdcpp_cxxabi1002__': <capsule object NULL at 0x7eff715161e0>, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f0084141610>>}\n",
      "hehe0 torch <module 'torch' from '/home/hemanthgaddey/Documents/tdanet_/venv3.6/lib/python3.6/site-packages/torch/__init__.py'>\n",
      "hehe0 init_net <function init_net at 0x7eff5e1d57a0>\n",
      "hehe0 CNN_ENCODER <class 'model.cnn_encoder.CNN_ENCODER'>\n",
      "hehe0 RNN_ENCODER <class 'model.rnn_encoder.RNN_ENCODER'>\n",
      "hehe0 AttTextualResEncoder <class 'model.attention_textual_resnet_encoder.AttTextualResEncoder'>\n",
      "hehe0 HiddenResGenerator <class 'model.hidden_resnet_generator.HiddenResGenerator'>\n",
      "hehe0 ResDiscriminator <class 'model.resnet_discriminator.ResDiscriminator'>\n",
      "hehe0 base_function <module 'model.base_function' from '/home/hemanthgaddey/Documents/tdanet_/tdanet/model/base_function.py'>\n",
      "hehe0 external_function <module 'model.external_function' from '/home/hemanthgaddey/Documents/tdanet_/tdanet/model/external_function.py'>\n",
      "hehe0 task <module 'util.task' from '/home/hemanthgaddey/Documents/tdanet_/tdanet/util/task.py'>\n",
      "hehe0 util <module 'util.util' from '/home/hemanthgaddey/Documents/tdanet_/tdanet/util/util.py'>\n",
      "hehe0 itertools <module 'itertools' (built-in)>\n",
      "hehe0 TextConfig <class 'options.global_config.TextConfig'>\n",
      "hehe0 pickle <module 'pickle' from '/home/hemanthgaddey/.pyenv/versions/3.6.15/lib/python3.6/pickle.py'>\n",
      "hehe0 copy <module 'copy' from '/home/hemanthgaddey/.pyenv/versions/3.6.15/lib/python3.6/copy.py'>\n",
      "hehe0 os <module 'os' from '/home/hemanthgaddey/.pyenv/versions/3.6.15/lib/python3.6/os.py'>\n",
      "hehe0 TDAnet <class 'model.tdanet_model.TDAnet'>\n",
      "foundit\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[] <class 'list'>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AttTextualResEncoder(\n",
      "  (block0): ResBlockEncoderOptimized(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (1): LeakyReLU(negative_slope=0.1)\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_attention): ImageTextAttention(\n",
      "    (conv_image): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (sm): Softmax(dim=None)\n",
      "    (sigmoid): Sigmoid()\n",
      "    (pooling_layer): AdaptiveMaxPool2d(output_size=1)\n",
      "  )\n",
      "  (encoder0): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder1): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder2): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder3): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (infer_prior0): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (infer_prior1): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (infer_prior2): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (infer_prior3): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (infer_prior4): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (infer_prior5): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (posterior): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (prior): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "total number of parameters: 23.233 M\n",
      "initialize network with orthogonal\n",
      "HiddenResGenerator(\n",
      "  (generator): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): ReLU()\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (f_transformer): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): ReLU()\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder0): ResBlockDecoder(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU()\n",
      "      (5): SpectralNorm(\n",
      "        (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder1): ResBlockDecoder(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU()\n",
      "      (5): SpectralNorm(\n",
      "        (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out1): Output(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(256, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(256, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "      )\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (attn1): Auto_Attn(\n",
      "    (query_conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (softmax): Softmax(dim=-1)\n",
      "    (model): ResBlock(\n",
      "      (conv1): SpectralNorm(\n",
      "        (module): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): SpectralNorm(\n",
      "        (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bypass): SpectralNorm(\n",
      "        (module): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (model): Sequential(\n",
      "        (0): LeakyReLU(negative_slope=0.01)\n",
      "        (1): SpectralNorm(\n",
      "          (module): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "        (3): SpectralNorm(\n",
      "          (module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): SpectralNorm(\n",
      "          (module): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder2): ResBlockDecoder(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(259, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): ConvTranspose2d(259, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): BatchNorm2d(259, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(259, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU()\n",
      "      (5): SpectralNorm(\n",
      "        (module): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): ConvTranspose2d(259, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out2): Output(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "      )\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (decoder3): ResBlockDecoder(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(131, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): ConvTranspose2d(131, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): BatchNorm2d(131, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(131, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU()\n",
      "      (5): SpectralNorm(\n",
      "        (module): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): ConvTranspose2d(131, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out3): Output(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "      )\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (decoder4): ResBlockDecoder(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(67, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): ConvTranspose2d(67, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): BatchNorm2d(67, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(67, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): ReLU()\n",
      "      (5): SpectralNorm(\n",
      "        (module): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): ConvTranspose2d(67, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out4): Output(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "      )\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "total number of parameters: 10.311 M\n",
      "initialize network with orthogonal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResDiscriminator(\n",
      "  (nonlinearity): LeakyReLU(negative_slope=0.1)\n",
      "  (block0): ResBlockEncoderOptimized(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (1): LeakyReLU(negative_slope=0.1)\n",
      "      (2): SpectralNorm(\n",
      "        (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder0): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder1): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (attn2): Auto_Attn(\n",
      "    (query_conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (softmax): Softmax(dim=-1)\n",
      "    (model): ResBlock(\n",
      "      (conv1): SpectralNorm(\n",
      "        (module): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bypass): SpectralNorm(\n",
      "        (module): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (model): Sequential(\n",
      "        (0): LeakyReLU(negative_slope=0.01)\n",
      "        (1): SpectralNorm(\n",
      "          (module): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "        (3): SpectralNorm(\n",
      "          (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): SpectralNorm(\n",
      "          (module): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder2): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder3): ResBlock(\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (block1): ResBlock(\n",
      "    (conv1): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv2): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (bypass): SpectralNorm(\n",
      "      (module): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (model): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.1)\n",
      "      (1): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "      (3): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): SpectralNorm(\n",
      "        (module): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv): SpectralNorm(\n",
      "    (module): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "total number of parameters: 1.591 M\n",
      "initialize network with orthogonal\n",
      "model [TDAnet] was created\n",
      "\n",
      " Training epoch: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-39c929f20132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n Training epoch: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0miter_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tdanet_/venv3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tdanet_/venv3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tdanet_/venv3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.15/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.15/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###opt = TrainOptions().parse()\n",
    "\n",
    "print('number of training images =',dataset_size)\n",
    "# create a model\n",
    "model = create_model(opt)\n",
    "\n",
    "# create a visualizer\n",
    "#visualizer = Visualizer(opt)\n",
    "\n",
    "# training flag\n",
    "keep_training = True\n",
    "max_iteration = opt.niter+opt.niter_decay\n",
    "epoch = 0\n",
    "total_iteration = opt.iter_count\n",
    "\n",
    "# training process\n",
    "while(keep_training):\n",
    "    epoch_start_time = time.time()\n",
    "    epoch+=1\n",
    "    print('\\n Training epoch: %d' % epoch)\n",
    "\n",
    "    for i, data in enumerate(dataset):\n",
    "        dataset.epoch = epoch - 1\n",
    "        iter_start_time = time.time()\n",
    "        total_iteration += 1\n",
    "        model.set_input(data)\n",
    "        model.optimize_parameters()\n",
    "        if total_iteration % opt.print_freq == 0:\n",
    "            losses = model.get_current_errors()\n",
    "            \n",
    "        # save the latest model every <save_latest_freq> iterations to the disk\n",
    "        if total_iteration % opt.save_latest_freq == 0:\n",
    "            print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_iteration))\n",
    "            model.save_networks('latest')\n",
    "\n",
    "        # save the model every <save_iter_freq> iterations to the disk\n",
    "        if total_iteration % opt.save_iters_freq == 0:\n",
    "            print('saving the model of iterations %d' % total_iteration)\n",
    "            model.save_networks(total_iteration)\n",
    "\n",
    "        if total_iteration > max_iteration:\n",
    "            keep_training = False\n",
    "            break\n",
    "\n",
    "    model.update_learning_rate()\n",
    "\n",
    "    print('\\nEnd training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
